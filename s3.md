# Storage

* S3 FAQ, **read before exam**: https://www.google.co.uk/search?rlz=1C5CHFA_enGB693GB693&q=s3+faq&spell=1&sa=X&ved=0ahUKEwiR8-7Mya_WAhVFF8AKHTpYDRMQBQglKAA&biw=1440&bih=803
* S3 is flat file/object based storage, as opposed to block based storage. Cannot install software/DBs.
* Data is spread across multiple locations and devices.
* Files can be 0b to 5Tb. Unlimited storage - more SAN arrays provisioned as needed behinds the scenes.
* Global namespace - must be unique.
* S3 is a key-value store. Have key (filename), value, version ID, metadata (e.g. date updated), subresources (access control lists and torrent).
  * Access control lists can be set for individual files, or at bucket level. Can also control bucket access via bucket policies.
  * S3 supports bittorrent protocol.
* Need to be careful of having same start of filename e.g. date - will all be stored in same physical area, producing performance issues. Can get round this by salting start of filename.
* Built for 99.99% availability - Amazon guarantee 99.9% via SLA. Amazon guarantee 11 9s for S3 information durability, i.e. won't lose files.
* Can encrypt files on S3, different options available.
* S3 has tiered storage options, most expensive first:
  * S3: 99.9 availability, 11 9s durability. Stored across multiple facilities. Designed to withstand loss of 2 at a time.
  * Reduced Redundancy Storage (RRS) - 99.99% availability, 99.99% durability. Designed to withstand loss of a single facility (Note price difference vs normal S3 is trivial). Would be used for files that can easily be regenerated.
  * S3 IA (Infrequently Accessed). Lower fee than S3, but charged retrieval fee. Example use case is audit logs. Has 128kB minimum object size - would rule out audit logs etc.
  * Glacier. Lowest fee, takes 3-5 hours to retrieve data. Used for archival only. 11 9s durability and doesn't quote an availability figure.
* All options have ms latency and SSL support.

## Practical: setting up buckets

* Can only use lower case characters for bucket name.
* DNS format is always: http://s3-`region`.amazonaws.com/`name` e.g. http://s3-eu-west-2.amazonaws.com/example
* Can be used for static hosting, as long as does not require server side code (as object storage)
* Once enabled, versioning can't be turned off fully, only suspended. Bucket needs to be deleted to get rid of it completely.
* Versioning allows objects to be restored once deleted. To restore, the delete marker needs to be deleted.
* By default, simple GET request will retrieve most recent version of an object. Can use `versionId` query parameter to request a specific version.
* Versioning: can enforce MFA for deleting objects. More to prevent accidental deleting.

## Charges

* You pay for:
  * Storage (note IA will charge for 128kb storage if file size lower)
  * Requests
  * Data transfers (including replication, and transfers to other AWS services as well as outside internet).
* Optional: Storage Management - can tag objects via additional metadata so can see which app is using most space.
* Optional: S3 transfer acceleration. Use edge locations for uploads and downloads.
* Need to be a bit careful with old versions, if versioning turned on - can take up lots of space. Might want to archive old versions to Glacier. Versioning integrates well with these lifecycle rules.

## Data consistency model

* Will always get 200 status code if upload successful.
* Read after write consistency for PUSH of new objects - real time, i.e. can read straight away.
* Eventual consistency for PUTS and DELETES - not real time.
* Updates are atomic - will either get old data or new data. Can never get partial data.
* This is because when updating or deleting a file, it may not have replicated to other notes by the time you make a read request.

## Lifecycle Management

* Can apply rules to move current or previous versions to S3-IA, and/or Glacier. Can only define rules in number of days after created - no way of resetting if accessed (although could code this, using CouldTrail logs to work out when last accessed).
* Can apply rules to delete previous versions only (if versioning turned on - doesn't necessarily have to be).
* Won't transition to IA if under 128kb (sensible money saving rule).

## Security and Encryption

* By default, all newly created buckets are priviate.
* Three [different types of security](https://aws.amazon.com/blogs/security/iam-policies-and-bucket-policies-and-acls-oh-my-controlling-access-to-s3-resources/):
  * ACL = Access Control List. Can be applied to a whole bucket or to individual items. Legacy way of securing buckets, best ignored (it would be a poor architecture if you ended up having to control access at object level).
  * Bucket Policy: policy attached specifically to an S3 bucket (can't be attached to object). Lists principal(s): users, groups or roles.
  * IAM Policy: policy that can cover all of AWS, not just S3. Does not list principals, as always explicitly attached to a principal.
* S3 buckets can be configured to create access logs - can be done to another bucket, or another AWS account.
* Different S3 encryption methods:
  * In Transit:
    * SSL/TLS, i.e. HTTPS
  * At Rest:
    * Server Side Encryption:
      * S3 Managed Keys (SSE-S3): each object encrypted with unique key. Key itself encrypted with master key. ALl handled by AWS. All managed for you by AWS.
      * AWS Key Management Service, Managed Keys (SSE-KMS): separate permissions for envelope key, better protection for key. Provides audit trail of key use. Can create and manage keys yourself.
      * Customer Provided Keys (SSE-C): AWS still manage encryption/decryption.
    * Client Side Encryption: encrypt on client side then upload to S3.